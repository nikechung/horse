{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import horse \n",
    "import horse_history\n",
    "import feature_analysis\n",
    "import algorithm_analysis\n",
    "from horse import getHorseData\n",
    "from horse_history import getHorseHistory, prepareData, removeOutlier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_data = getHorseData('../horses.csv')\n",
    "horse_race_history = getHorseHistory('../horses_history.csv', horse_data)\n",
    "horse_race_data = prepareData(horse_race_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "horse_id             8898\n",
       "race_id              8898\n",
       "result               8898\n",
       "date                 8898\n",
       "location_run         8898\n",
       "distance             8898\n",
       "G                    8898\n",
       "race_class           8898\n",
       "dr                   8898\n",
       "rtg                  8898\n",
       "trainer              8898\n",
       "jockey               8898\n",
       "lbw                  8898\n",
       "win_odds             8898\n",
       "act_wt               8898\n",
       "running_position     8898\n",
       "finish_time          8898\n",
       "weight               8898\n",
       "gear                 8898\n",
       "month                8898\n",
       "location             8898\n",
       "track                8898\n",
       "course               8898\n",
       "finish_time_ms       8898\n",
       "speed_m_s            8898\n",
       "horse_country        8898\n",
       "horse_age            8898\n",
       "horse_owner          8898\n",
       "horse_import_type    8898\n",
       "horse_color          8898\n",
       "horse_sex            8898\n",
       "horse_sire           8898\n",
       "horse_dam            8898\n",
       "horse_dam_sire       8898\n",
       "distance_km          8898\n",
       "quarter              8898\n",
       "no_of_turns          8898\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horse_race_data = removeOutlier(horse_race_data)\n",
    "horse_race_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_race_data[\"quarter\"] = horse_race_data[\"quarter\"].astype('int')\n",
    "horse_race_data = horse_race_data[horse_race_data['rtg'] != \"--\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.1\n",
      "[CV 2/5; 1/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.1\n",
      "[CV 3/5; 1/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.1\n",
      "[CV 4/5; 1/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.1\n",
      "[CV 1/5; 1/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.1;, score=0.131 total time=   2.7s\n",
      "[CV 2/5; 1/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.1;, score=0.125 total time=   2.2s\n",
      "[CV 3/5; 1/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.1;, score=0.130 total time=   2.1s\n",
      "[CV 5/5; 1/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.1\n",
      "[CV 4/5; 1/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.1;, score=0.134 total time=   2.1s\n",
      "[CV 1/5; 2/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 2/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 2/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 1/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.1;, score=0.130 total time=   2.2s\n",
      "[CV 4/5; 2/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 2/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5;, score=0.126 total time=   4.1s\n",
      "[CV 1/5; 2/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5;, score=0.131 total time=   4.1s\n",
      "[CV 5/5; 2/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 3/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 2/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5;, score=0.130 total time=   4.1s\n",
      "[CV 2/5; 3/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 2/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5;, score=0.135 total time=   4.4s\n",
      "[CV 3/5; 3/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 2/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=0.5;, score=0.131 total time=   4.7s\n",
      "[CV 4/5; 3/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 3/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1.0;, score=0.131 total time=   5.8s\n",
      "[CV 5/5; 3/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 3/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1.0;, score=0.126 total time=   5.6s\n",
      "[CV 1/5; 4/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.1\n",
      "[CV 3/5; 3/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1.0;, score=0.130 total time=   5.4s\n",
      "[CV 2/5; 4/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.1\n",
      "[CV 4/5; 3/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1.0;, score=0.135 total time=   5.1s\n",
      "[CV 3/5; 4/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.1\n",
      "[CV 1/5; 4/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.1;, score=0.239 total time=   4.3s\n",
      "[CV 4/5; 4/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.1\n",
      "[CV 5/5; 3/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=100, subsample=1.0;, score=0.131 total time=   5.4s\n",
      "[CV 5/5; 4/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.1\n",
      "[CV 2/5; 4/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.1;, score=0.229 total time=   4.1s\n",
      "[CV 1/5; 5/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5\n",
      "[CV 3/5; 4/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.1;, score=0.240 total time=   4.4s\n",
      "[CV 2/5; 5/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5\n",
      "[CV 4/5; 4/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.1;, score=0.245 total time=   4.3s\n",
      "[CV 3/5; 5/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5\n",
      "[CV 5/5; 4/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.1;, score=0.238 total time=   4.6s\n",
      "[CV 4/5; 5/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5\n",
      "[CV 1/5; 5/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5;, score=0.240 total time=   8.9s\n",
      "[CV 5/5; 5/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5\n",
      "[CV 2/5; 5/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5;, score=0.230 total time=   8.7s\n",
      "[CV 1/5; 6/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1.0\n",
      "[CV 3/5; 5/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5;, score=0.240 total time=   8.8s\n",
      "[CV 2/5; 6/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1.0\n",
      "[CV 4/5; 5/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5;, score=0.245 total time=   8.7s\n",
      "[CV 3/5; 6/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1.0\n",
      "[CV 5/5; 5/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=0.5;, score=0.239 total time=   7.4s\n",
      "[CV 4/5; 6/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1.0\n",
      "[CV 1/5; 6/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1.0;, score=0.239 total time=  10.0s\n",
      "[CV 5/5; 6/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1.0\n",
      "[CV 2/5; 6/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1.0;, score=0.230 total time=   9.8s\n",
      "[CV 1/5; 7/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.1\n",
      "[CV 3/5; 6/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1.0;, score=0.239 total time=   9.8s\n",
      "[CV 2/5; 7/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.1\n",
      "[CV 4/5; 6/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1.0;, score=0.246 total time=  10.3s\n",
      "[CV 3/5; 7/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.1\n",
      "[CV 1/5; 7/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.1;, score=0.329 total time=   5.6s\n",
      "[CV 4/5; 7/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.1\n",
      "[CV 2/5; 7/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.1;, score=0.316 total time=   6.4s\n",
      "[CV 5/5; 7/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.1\n",
      "[CV 5/5; 6/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=200, subsample=1.0;, score=0.239 total time=  10.2s\n",
      "[CV 1/5; 8/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.5\n",
      "[CV 3/5; 7/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.1;, score=0.330 total time=   5.8s\n",
      "[CV 2/5; 8/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.5\n",
      "[CV 4/5; 7/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.1;, score=0.335 total time=   5.8s\n",
      "[CV 3/5; 8/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.5\n",
      "[CV 5/5; 7/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.1;, score=0.328 total time=   5.7s\n",
      "[CV 4/5; 8/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.5\n",
      "[CV 1/5; 8/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.5;, score=0.329 total time=  11.3s\n",
      "[CV 5/5; 8/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.5\n",
      "[CV 2/5; 8/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.5;, score=0.317 total time=  11.4s\n",
      "[CV 1/5; 9/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=1.0\n",
      "[CV 3/5; 8/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.5;, score=0.329 total time=  11.3s\n",
      "[CV 2/5; 9/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=1.0\n",
      "[CV 4/5; 8/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.5;, score=0.336 total time=  12.1s\n",
      "[CV 3/5; 9/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=1.0\n",
      "[CV 5/5; 8/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=0.5;, score=0.328 total time=  12.3s\n",
      "[CV 4/5; 9/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=1.0\n",
      "[CV 1/5; 9/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=1.0;, score=0.328 total time=  16.6s\n",
      "[CV 5/5; 9/432] START learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=1.0\n",
      "[CV 2/5; 9/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=1.0;, score=0.317 total time=  16.5s\n",
      "[CV 1/5; 10/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.1\n",
      "[CV 3/5; 9/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=1.0;, score=0.329 total time=  16.3s\n",
      "[CV 2/5; 10/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.1\n",
      "[CV 1/5; 10/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.1;, score=0.137 total time=   3.2s\n",
      "[CV 3/5; 10/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.1\n",
      "[CV 2/5; 10/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.1;, score=0.131 total time=   2.7s\n",
      "[CV 4/5; 10/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.1\n",
      "[CV 3/5; 10/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.1;, score=0.136 total time=   2.9s\n",
      "[CV 5/5; 10/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.1\n",
      "[CV 4/5; 10/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.1;, score=0.139 total time=   2.6s\n",
      "[CV 1/5; 11/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 10/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.1;, score=0.135 total time=   2.2s\n",
      "[CV 2/5; 11/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 9/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=1.0;, score=0.336 total time=  16.0s\n",
      "[CV 3/5; 11/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 11/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5;, score=0.138 total time=   5.1s\n",
      "[CV 4/5; 11/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 11/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5;, score=0.132 total time=   5.4s\n",
      "[CV 5/5; 11/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 9/432] END learning_rate=0.001, loss=squared_error, max_depth=3, n_estimators=300, subsample=1.0;, score=0.328 total time=  16.0s\n",
      "[CV 1/5; 12/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1.0\n",
      "[CV 3/5; 11/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5;, score=0.137 total time=   5.9s\n",
      "[CV 2/5; 12/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 11/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5;, score=0.140 total time=   6.1s\n",
      "[CV 3/5; 12/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 11/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=0.5;, score=0.137 total time=   6.1s\n",
      "[CV 4/5; 12/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 12/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1.0;, score=0.138 total time=   8.1s\n",
      "[CV 5/5; 12/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 12/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1.0;, score=0.132 total time=   7.9s\n",
      "[CV 1/5; 13/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.1\n",
      "[CV 3/5; 12/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1.0;, score=0.137 total time=   7.4s\n",
      "[CV 2/5; 13/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.1\n",
      "[CV 4/5; 12/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1.0;, score=0.140 total time=   7.6s\n",
      "[CV 3/5; 13/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.1\n",
      "[CV 1/5; 13/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.1;, score=0.250 total time=   4.4s\n",
      "[CV 4/5; 13/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.1\n",
      "[CV 2/5; 13/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.1;, score=0.241 total time=   5.1s\n",
      "[CV 5/5; 13/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.1\n",
      "[CV 5/5; 12/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=100, subsample=1.0;, score=0.137 total time=   8.0s\n",
      "[CV 1/5; 14/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5\n",
      "[CV 3/5; 13/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.1;, score=0.251 total time=   4.9s\n",
      "[CV 2/5; 14/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5\n",
      "[CV 4/5; 13/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.1;, score=0.253 total time=   5.6s\n",
      "[CV 3/5; 14/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5\n",
      "[CV 5/5; 13/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.1;, score=0.248 total time=   4.6s\n",
      "[CV 4/5; 14/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5\n",
      "[CV 1/5; 14/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5;, score=0.251 total time=   9.3s\n",
      "[CV 5/5; 14/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5\n",
      "[CV 2/5; 14/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5;, score=0.242 total time=   8.9s\n",
      "[CV 1/5; 15/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1.0\n",
      "[CV 3/5; 14/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5;, score=0.252 total time=   8.6s\n",
      "[CV 2/5; 15/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1.0\n",
      "[CV 4/5; 14/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5;, score=0.255 total time=   8.6s\n",
      "[CV 3/5; 15/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1.0\n",
      "[CV 5/5; 14/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=0.5;, score=0.250 total time=   8.9s\n",
      "[CV 4/5; 15/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1.0\n",
      "[CV 1/5; 15/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1.0;, score=0.251 total time=  13.1s\n",
      "[CV 5/5; 15/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1.0\n",
      "[CV 2/5; 15/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1.0;, score=0.241 total time=  12.8s\n",
      "[CV 1/5; 16/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.1\n",
      "[CV 3/5; 15/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1.0;, score=0.252 total time=  12.8s\n",
      "[CV 2/5; 16/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.1\n",
      "[CV 1/5; 16/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.1;, score=0.342 total time=   5.7s\n",
      "[CV 3/5; 16/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.1\n",
      "[CV 4/5; 15/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1.0;, score=0.254 total time=  12.7s\n",
      "[CV 4/5; 16/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.1\n",
      "[CV 2/5; 16/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.1;, score=0.330 total time=   5.7s\n",
      "[CV 5/5; 16/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.1\n",
      "[CV 3/5; 16/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.1;, score=0.344 total time=   5.1s\n",
      "[CV 1/5; 17/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.5\n",
      "[CV 5/5; 15/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=200, subsample=1.0;, score=0.250 total time=  12.2s\n",
      "[CV 2/5; 17/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.5\n",
      "[CV 4/5; 16/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.1;, score=0.345 total time=   5.1s\n",
      "[CV 3/5; 17/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.5\n",
      "[CV 5/5; 16/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.1;, score=0.340 total time=   5.2s\n",
      "[CV 4/5; 17/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.5\n",
      "[CV 1/5; 17/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.5;, score=0.344 total time=  11.7s\n",
      "[CV 5/5; 17/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.5\n",
      "[CV 2/5; 17/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.5;, score=0.332 total time=  11.7s\n",
      "[CV 1/5; 18/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=1.0\n",
      "[CV 3/5; 17/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.5;, score=0.346 total time=  11.4s\n",
      "[CV 2/5; 18/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=1.0\n",
      "[CV 4/5; 17/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.5;, score=0.348 total time=  11.6s\n",
      "[CV 3/5; 18/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=1.0\n",
      "[CV 5/5; 17/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=0.5;, score=0.342 total time=  13.2s\n",
      "[CV 4/5; 18/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=1.0\n",
      "[CV 1/5; 18/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=1.0;, score=0.345 total time=  20.7s\n",
      "[CV 5/5; 18/432] START learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=1.0\n",
      "[CV 2/5; 18/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=1.0;, score=0.331 total time=  20.7s\n",
      "[CV 1/5; 19/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.1\n",
      "[CV 3/5; 18/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=1.0;, score=0.346 total time=  20.8s\n",
      "[CV 2/5; 19/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.1\n",
      "[CV 1/5; 19/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.1;, score=0.138 total time=   3.0s\n",
      "[CV 3/5; 19/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.1\n",
      "[CV 2/5; 19/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.1;, score=0.133 total time=   3.3s\n",
      "[CV 4/5; 19/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.1\n",
      "[CV 3/5; 19/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.1;, score=0.138 total time=   4.0s\n",
      "[CV 5/5; 19/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.1\n",
      "[CV 4/5; 19/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.1;, score=0.141 total time=   3.9s\n",
      "[CV 1/5; 20/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 19/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.1;, score=0.137 total time=   2.9s\n",
      "[CV 2/5; 20/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 18/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=1.0;, score=0.347 total time=  23.6s\n",
      "[CV 3/5; 20/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 20/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.5;, score=0.139 total time=   6.8s\n",
      "[CV 4/5; 20/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 20/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.5;, score=0.135 total time=   6.6s\n",
      "[CV 5/5; 20/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 20/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.5;, score=0.139 total time=   6.1s\n",
      "[CV 1/5; 21/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 20/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.5;, score=0.142 total time=   6.1s\n",
      "[CV 2/5; 21/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 18/432] END learning_rate=0.001, loss=squared_error, max_depth=5, n_estimators=300, subsample=1.0;, score=0.343 total time=  22.5s\n",
      "[CV 3/5; 21/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 20/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=0.5;, score=0.138 total time=   5.8s\n",
      "[CV 4/5; 21/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 21/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=1.0;, score=0.140 total time=   8.3s\n",
      "[CV 2/5; 21/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=1.0;, score=0.134 total time=   8.3s\n",
      "[CV 5/5; 21/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 22/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.1\n",
      "[CV 3/5; 21/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=1.0;, score=0.139 total time=   8.2s\n",
      "[CV 2/5; 22/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.1\n",
      "[CV 4/5; 21/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=1.0;, score=0.142 total time=   8.3s\n",
      "[CV 3/5; 22/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.1\n",
      "[CV 1/5; 22/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.1;, score=0.251 total time=   4.7s\n",
      "[CV 4/5; 22/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.1\n",
      "[CV 2/5; 22/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.1;, score=0.243 total time=   4.7s\n",
      "[CV 5/5; 22/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.1\n",
      "[CV 3/5; 22/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.1;, score=0.255 total time=   5.2s\n",
      "[CV 1/5; 23/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.5\n",
      "[CV 5/5; 21/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=100, subsample=1.0;, score=0.138 total time=   9.9s\n",
      "[CV 2/5; 23/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.5\n",
      "[CV 4/5; 22/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.1;, score=0.254 total time=   5.5s\n",
      "[CV 3/5; 23/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.5\n",
      "[CV 5/5; 22/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.1;, score=0.250 total time=   5.2s\n",
      "[CV 4/5; 23/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.5\n",
      "[CV 1/5; 23/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.5;, score=0.254 total time=  12.4s\n",
      "[CV 5/5; 23/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.5\n",
      "[CV 2/5; 23/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.5;, score=0.246 total time=  12.0s\n",
      "[CV 1/5; 24/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=1.0\n",
      "[CV 3/5; 23/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.5;, score=0.256 total time=  12.1s\n",
      "[CV 2/5; 24/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=1.0\n",
      "[CV 4/5; 23/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.5;, score=0.258 total time=  12.0s\n",
      "[CV 3/5; 24/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=1.0\n",
      "[CV 5/5; 23/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=0.5;, score=0.252 total time=  12.1s\n",
      "[CV 4/5; 24/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=1.0\n",
      "[CV 1/5; 24/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=1.0;, score=0.255 total time=  18.3s\n",
      "[CV 5/5; 24/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=1.0\n",
      "[CV 2/5; 24/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=1.0;, score=0.244 total time=  18.3s\n",
      "[CV 1/5; 25/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.1\n",
      "[CV 3/5; 24/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=1.0;, score=0.255 total time=  18.3s\n",
      "[CV 2/5; 25/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.1\n",
      "[CV 1/5; 25/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.1;, score=0.346 total time=   7.0s\n",
      "[CV 3/5; 25/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.1\n",
      "[CV 2/5; 25/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.1;, score=0.335 total time=   7.0s\n",
      "[CV 4/5; 25/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.1\n",
      "[CV 4/5; 24/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=1.0;, score=0.257 total time=  17.7s\n",
      "[CV 5/5; 25/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.1\n",
      "[CV 3/5; 25/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.1;, score=0.348 total time=   6.5s\n",
      "[CV 1/5; 26/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.5\n",
      "[CV 4/5; 25/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.1;, score=0.350 total time=   6.6s\n",
      "[CV 2/5; 26/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.5\n",
      "[CV 5/5; 25/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.1;, score=0.342 total time=   7.1s\n",
      "[CV 3/5; 26/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.5\n",
      "[CV 5/5; 24/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=200, subsample=1.0;, score=0.252 total time=  18.3s\n",
      "[CV 4/5; 26/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.5\n",
      "[CV 1/5; 26/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.5;, score=0.348 total time=  20.3s\n",
      "[CV 5/5; 26/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.5\n",
      "[CV 2/5; 26/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.5;, score=0.338 total time=  20.2s\n",
      "[CV 1/5; 27/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=1.0\n",
      "[CV 3/5; 26/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.5;, score=0.352 total time=  20.1s\n",
      "[CV 2/5; 27/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=1.0\n",
      "[CV 4/5; 26/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.5;, score=0.353 total time=  19.8s\n",
      "[CV 3/5; 27/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=1.0\n",
      "[CV 5/5; 26/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=0.5;, score=0.345 total time=  16.8s\n",
      "[CV 4/5; 27/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=1.0\n",
      "[CV 1/5; 27/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=1.0;, score=0.348 total time=  25.6s\n",
      "[CV 5/5; 27/432] START learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=1.0\n",
      "[CV 2/5; 27/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=1.0;, score=0.336 total time=  25.8s\n",
      "[CV 1/5; 28/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.1\n",
      "[CV 3/5; 27/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=1.0;, score=0.350 total time=  25.4s\n",
      "[CV 2/5; 28/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.1\n",
      "[CV 1/5; 28/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.1;, score=0.101 total time=   3.5s\n",
      "[CV 3/5; 28/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.1\n",
      "[CV 2/5; 28/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.1;, score=0.103 total time=   3.5s\n",
      "[CV 4/5; 28/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.1\n",
      "[CV 3/5; 28/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.1;, score=0.081 total time=   3.6s\n",
      "[CV 5/5; 28/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.1\n",
      "[CV 4/5; 28/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.1;, score=0.106 total time=   3.4s\n",
      "[CV 1/5; 29/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 28/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.1;, score=0.107 total time=   3.4s\n",
      "[CV 2/5; 29/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 29/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5;, score=0.103 total time=   5.2s\n",
      "[CV 3/5; 29/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 29/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5;, score=0.107 total time=   5.0s\n",
      "[CV 4/5; 29/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 27/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=1.0;, score=0.351 total time=  28.1s\n",
      "[CV 5/5; 29/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 29/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5;, score=0.085 total time=   5.7s\n",
      "[CV 1/5; 30/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1.0\n",
      "[CV 4/5; 29/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5;, score=0.107 total time=   5.4s\n",
      "[CV 2/5; 30/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 29/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=0.5;, score=0.110 total time=   4.8s\n",
      "[CV 3/5; 30/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1.0\n",
      "[CV 1/5; 30/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1.0;, score=0.102 total time=   5.7s\n",
      "[CV 4/5; 30/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1.0\n",
      "[CV 5/5; 27/432] END learning_rate=0.001, loss=squared_error, max_depth=7, n_estimators=300, subsample=1.0;, score=0.345 total time=  27.9s\n",
      "[CV 5/5; 30/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1.0\n",
      "[CV 2/5; 30/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1.0;, score=0.108 total time=   6.0s\n",
      "[CV 1/5; 31/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.1\n",
      "[CV 3/5; 30/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1.0;, score=0.085 total time=   5.7s\n",
      "[CV 2/5; 31/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.1\n",
      "[CV 4/5; 30/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1.0;, score=0.105 total time=   6.8s\n",
      "[CV 3/5; 31/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.1\n",
      "[CV 5/5; 30/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=100, subsample=1.0;, score=0.109 total time=   7.5s\n",
      "[CV 4/5; 31/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.1\n",
      "[CV 1/5; 31/432] END learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.1;, score=0.205 total time=   8.2s\n",
      "[CV 5/5; 31/432] START learning_rate=0.001, loss=absolute_error, max_depth=3, n_estimators=200, subsample=0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m y \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeed_m_s\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# model, score = algorithm_analysis.findBestAlgorithm(X, y)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm_analysis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindBestHyperParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGradientBoostingRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/horse/app/algorithm_analysis.py:49\u001b[0m, in \u001b[0;36mfindBestHyperParameter\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m     40\u001b[0m param_test \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuber\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantile\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]\n\u001b[1;32m     46\u001b[0m }\n\u001b[1;32m     48\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_test, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     51\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimal_features = ['horse_color',\n",
    "                    'horse_age',\n",
    "                    'race_class',\n",
    "                    'weight',\n",
    "                    'dr',\n",
    "                    'jockey',\n",
    "                    'distance_km',\n",
    "                    'quarter',\n",
    "                    'horse_dam',\n",
    "                    'no_of_turns', \n",
    "                    ]\n",
    "d = horse_race_data.dropna()\n",
    "X = d[optimal_features] \n",
    "y = d['speed_m_s']\n",
    "# model, score = algorithm_analysis.findBestAlgorithm(X, y)\n",
    "result = algorithm_analysis.findBestHyperParameter(GradientBoostingRegressor(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_quarter(month):\n",
    "    bins = [0, 3, 6, 9, 12]\n",
    "    labels = [1, 2, 3, 4]\n",
    "    quarter = pd.cut([month], bins=bins, labels=labels)[0]\n",
    "    return quarter\n",
    "\n",
    "# Example usage\n",
    "month = 1\n",
    "quarter = get_quarter(month)\n",
    "print(quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horse_id</th>\n",
       "      <th>race_id</th>\n",
       "      <th>result</th>\n",
       "      <th>date</th>\n",
       "      <th>location_run</th>\n",
       "      <th>distance</th>\n",
       "      <th>G</th>\n",
       "      <th>race_class</th>\n",
       "      <th>dr</th>\n",
       "      <th>rtg</th>\n",
       "      <th>...</th>\n",
       "      <th>horse_owner</th>\n",
       "      <th>horse_import_type</th>\n",
       "      <th>horse_color</th>\n",
       "      <th>horse_sex</th>\n",
       "      <th>horse_sire</th>\n",
       "      <th>horse_dam</th>\n",
       "      <th>horse_dam_sire</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>quarter</th>\n",
       "      <th>no_of_turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C238</td>\n",
       "      <td>623</td>\n",
       "      <td>04</td>\n",
       "      <td>2024-04-28</td>\n",
       "      <td>ST / Turf / \"A\"</td>\n",
       "      <td>1600</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "      <td>...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C238</td>\n",
       "      <td>238</td>\n",
       "      <td>01</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>ST / Turf / \"A\"</td>\n",
       "      <td>1600</td>\n",
       "      <td>2.75</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C238</td>\n",
       "      <td>622</td>\n",
       "      <td>01</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>ST / Turf / \"A\"</td>\n",
       "      <td>1600</td>\n",
       "      <td>2.75</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C238</td>\n",
       "      <td>451</td>\n",
       "      <td>01</td>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>ST / Turf / \"A+3\"</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C238</td>\n",
       "      <td>375</td>\n",
       "      <td>01</td>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>ST / Turf / \"A+3\"</td>\n",
       "      <td>1600</td>\n",
       "      <td>2.75</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>J165</td>\n",
       "      <td>694</td>\n",
       "      <td>13</td>\n",
       "      <td>2024-05-26</td>\n",
       "      <td>ST / Turf / \"A\"</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>274.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9086</th>\n",
       "      <td>J371</td>\n",
       "      <td>802</td>\n",
       "      <td>11</td>\n",
       "      <td>2024-07-06</td>\n",
       "      <td>ST / Turf / \"C\"</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.50</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>276.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>J371</td>\n",
       "      <td>751</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>ST / Turf / \"C+3\"</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.25</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>276.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>J308</td>\n",
       "      <td>751</td>\n",
       "      <td>09</td>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>ST / Turf / \"C+3\"</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.25</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>188.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>J413</td>\n",
       "      <td>694</td>\n",
       "      <td>14</td>\n",
       "      <td>2024-05-26</td>\n",
       "      <td>ST / Turf / \"A\"</td>\n",
       "      <td>1200</td>\n",
       "      <td>2.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>188.5</td>\n",
       "      <td>209.5</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8905 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     horse_id race_id result       date       location_run  distance     G  \\\n",
       "0        C238     623     04 2024-04-28    ST / Turf / \"A\"      1600  3.25   \n",
       "1        C238     238     01 2023-12-10    ST / Turf / \"A\"      1600  2.75   \n",
       "2        C238     622     01 2023-04-30    ST / Turf / \"A\"      1600  2.75   \n",
       "3        C238     451     01 2023-02-26  ST / Turf / \"A+3\"      2000  2.50   \n",
       "4        C238     375     01 2023-01-29  ST / Turf / \"A+3\"      1600  2.75   \n",
       "...       ...     ...    ...        ...                ...       ...   ...   \n",
       "9085     J165     694     13 2024-05-26    ST / Turf / \"A\"      1200  2.75   \n",
       "9086     J371     802     11 2024-07-06    ST / Turf / \"C\"      1200  2.50   \n",
       "9087     J371     751     10 2024-06-15  ST / Turf / \"C+3\"      1000  3.25   \n",
       "9088     J308     751     09 2024-06-15  ST / Turf / \"C+3\"      1000  3.25   \n",
       "9089     J413     694     14 2024-05-26    ST / Turf / \"A\"      1200  2.75   \n",
       "\n",
       "      race_class  dr  rtg  ...  horse_owner  horse_import_type horse_color  \\\n",
       "0            4.0   7  133  ...        339.0                3.0         4.0   \n",
       "1            4.0  14  131  ...        339.0                3.0         4.0   \n",
       "2            4.0   6  131  ...        339.0                3.0         4.0   \n",
       "3            4.0   4  131  ...        339.0                3.0         4.0   \n",
       "4            4.0   2  130  ...        339.0                3.0         4.0   \n",
       "...          ...  ..  ...  ...          ...                ...         ...   \n",
       "9085        12.0  12   --  ...        274.0                3.0         3.0   \n",
       "9086        12.0   2   --  ...        276.0                3.0         4.0   \n",
       "9087        12.0  11   --  ...        276.0                3.0         4.0   \n",
       "9088        12.0  10   --  ...        380.0                3.0         3.0   \n",
       "9089        12.0  13   --  ...         40.0                3.0         3.0   \n",
       "\n",
       "     horse_sex  horse_sire horse_dam horse_dam_sire  distance_km  quarter  \\\n",
       "0          2.0       129.0     368.0          160.0          1.6        2   \n",
       "1          2.0       129.0     368.0          160.0          1.6        4   \n",
       "2          2.0       129.0     368.0          160.0          1.6        2   \n",
       "3          2.0       129.0     368.0          160.0          2.0        1   \n",
       "4          2.0       129.0     368.0          160.0          1.6        1   \n",
       "...        ...         ...       ...            ...          ...      ...   \n",
       "9085       2.0       123.0     300.0          123.0          1.2        2   \n",
       "9086       2.0       143.0     383.0          252.0          1.2        3   \n",
       "9087       2.0       143.0     383.0          252.0          1.0        2   \n",
       "9088       2.0       143.0     415.0          188.5          1.0        2   \n",
       "9089       5.0       188.5     209.5          109.0          1.2        2   \n",
       "\n",
       "      no_of_turns  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "9085            0  \n",
       "9086            0  \n",
       "9087            0  \n",
       "9088            0  \n",
       "9089            0  \n",
       "\n",
       "[8905 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horse_race_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
